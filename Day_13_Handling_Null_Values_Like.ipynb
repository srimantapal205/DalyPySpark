{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "K9R9pyy1gU2Z"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *  # Import the function\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "from pyspark.sql.functions import regexp_replace, col\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive with a longer timeout\n",
        "# drive.mount('/content/drive', force_remount=True, timeout_ms=300000)\n",
        "\n",
        "# df_employee_data = \"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\"\n",
        "# employeeSechema = StructType([\n",
        "#     StructField(\"ID\",IntegerType() ,True),\n",
        "#     StructField(\"Name\",StringType() ,True),\n",
        "#     StructField(\"Age\",IntegerType() ,True),\n",
        "#     StructField(\"Salary\",FloatType() ,True),\n",
        "#     StructField(\"Joining_Date\",DateType() ,True),\n",
        "#     StructField(\"Department\",StringType() ,True),\n",
        "#     StructField(\"Performance_Rating\",IntegerType() ,True),\n",
        "#     StructField(\"Email\",StringType() ,True),\n",
        "#     StructField(\"Address\",StringType() ,True),\n",
        "#     StructField(\"Phone\",StringType() ,True)\n",
        "\n",
        "# ])\n",
        "# # Load the DataFrame with the defined schema\n",
        "# #df = spark.read.csv(path=df_employee_data, header=True, schema=employeeSechema)\n",
        "# df = spark.read.load(path=\"/content/drive/MyDrive/Colab Notebooks/dataSet/employee_data.csv\", format=\"csv\", header = True, schema=employeeSechema)\n",
        "# df.printSchema()\n",
        "# df.show(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Null Handling in Dataframe"
      ],
      "metadata": {
        "id": "knP5wytcsBpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data: sales data with nulls\n",
        "data = [\n",
        "      (\"John\", \"North\", 100, None),\n",
        "      (\"Doe\", \"East\", None, 50),\n",
        "      (None, \"West\", 150, 30),\n",
        "      (\"Alice\", None, 200, 40),\n",
        "      (\"Bob\", \"South\", None, None),\n",
        "      (None, None, None, None)\n",
        "  ]\n",
        "columns = [\"Name\", \"Region\", \"UnitsSold\", \"Revenue\"]\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "IFVtqhI2sDrR",
        "outputId": "145d0240-54a2-4f2a-e666-93cf77f52ffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---------+-------+\n",
            "| Name|Region|UnitsSold|Revenue|\n",
            "+-----+------+---------+-------+\n",
            "| John| North|      100|   NULL|\n",
            "|  Doe|  East|     NULL|     50|\n",
            "| NULL|  West|      150|     30|\n",
            "|Alice|  NULL|      200|     40|\n",
            "|  Bob| South|     NULL|   NULL|\n",
            "| NULL|  NULL|     NULL|   NULL|\n",
            "+-----+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Detecting Null Values:\n",
        "* The isNull() function identifies rows where a specified column has null values. The output shows a boolean flag for each row to indicate whether the value in the column is null."
      ],
      "metadata": {
        "id": "KYx6hsEYskB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecting Null Values in the \"Region\" column\n",
        "df.select(\"Name\", \"Region\", isnull(\"Region\").alias(\"is_Region_Null\")).show()"
      ],
      "metadata": {
        "id": "Axp49XOkspfE",
        "outputId": "e503e016-e6eb-48b1-b3b5-a97f0d64757d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+--------------+\n",
            "| Name|Region|is_Region_Null|\n",
            "+-----+------+--------------+\n",
            "| John| North|         false|\n",
            "|  Doe|  East|         false|\n",
            "| NULL|  West|         false|\n",
            "|Alice|  NULL|          true|\n",
            "|  Bob| South|         false|\n",
            "| NULL|  NULL|          true|\n",
            "+-----+------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Dropping Rows with Null Values:\n",
        "* dropna() removes rows that contain null values in any column when the default mode is used.\n",
        "* Specifying \"all\" ensures rows are only removed if all columns contain null values.\n",
        "* You can also apply null handling only on specific columns by providing a list of column names to the subset parameter."
      ],
      "metadata": {
        "id": "9FhBfMjStYRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Rows with Null values (if any value in the row is null)\n",
        "df2 = df.dropna()\n",
        "df2.show()"
      ],
      "metadata": {
        "id": "QVFdtogys1JA",
        "outputId": "3a1b548a-83fb-40b7-cf9b-9f2ee827e3e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+---------+-------+\n",
            "|Name|Region|UnitsSold|Revenue|\n",
            "+----+------+---------+-------+\n",
            "+----+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping rows where all values are null\n",
        "df3 = df.na.drop(\"all\")\n",
        "df3.show()"
      ],
      "metadata": {
        "id": "GSXkeSqVtpSh",
        "outputId": "d2ceb8c1-4b1d-4c28-9c5e-80058c43c2bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---------+-------+\n",
            "| Name|Region|UnitsSold|Revenue|\n",
            "+-----+------+---------+-------+\n",
            "| John| North|      100|   NULL|\n",
            "|  Doe|  East|     NULL|     50|\n",
            "| NULL|  West|      150|     30|\n",
            "|Alice|  NULL|      200|     40|\n",
            "|  Bob| South|     NULL|   NULL|\n",
            "+-----+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping Rows if null values in \"Name\" OR \"Region\" columns\n",
        "df4 = df.na.drop(\"all\", subset=[\"Name\", \"Region\"])\n",
        "df4.show()"
      ],
      "metadata": {
        "id": "ZhZ0wTu4uKTj",
        "outputId": "e86d51cd-296a-4e18-db6b-928532a63df7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---------+-------+\n",
            "| Name|Region|UnitsSold|Revenue|\n",
            "+-----+------+---------+-------+\n",
            "| John| North|      100|   NULL|\n",
            "|  Doe|  East|     NULL|     50|\n",
            "| NULL|  West|      150|     30|\n",
            "|Alice|  NULL|      200|     40|\n",
            "|  Bob| South|     NULL|   NULL|\n",
            "+-----+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filling Null Values:\n",
        "  * fillna() allows replacing null values with specified replacements, either for all columns or selectively.\n",
        "  * In the example, nulls in Region are replaced with \"Unknown\", while UnitsSold and Revenue nulls are filled with 0."
      ],
      "metadata": {
        "id": "5NQ_AeekOIyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filling nullvalue with specific values\n",
        "df5 = df.fillna({\"Region\": \"Unknown\", \"UnitsSold\": 0, \"Revenue\":0})\n",
        "df5.show()"
      ],
      "metadata": {
        "id": "BaLhinEQOPeM",
        "outputId": "bcd1a401-45a9-429f-baa5-278f26a59ab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+---------+-------+\n",
            "| Name| Region|UnitsSold|Revenue|\n",
            "+-----+-------+---------+-------+\n",
            "| John|  North|      100|      0|\n",
            "|  Doe|   East|        0|     50|\n",
            "| NULL|   West|      150|     30|\n",
            "|Alice|Unknown|      200|     40|\n",
            "|  Bob|  South|        0|      0|\n",
            "| NULL|Unknown|        0|      0|\n",
            "+-----+-------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling all null values in \"Region\" and \"name\" column\n",
        "df6 = df.na.fill(\"N/A\", subset=[\"Name\", \"Region\"])\n",
        "df6.show()\n"
      ],
      "metadata": {
        "id": "Lhcp1HPlOuim",
        "outputId": "30b2214c-905f-475e-8a0c-2609db3aa64e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---------+-------+\n",
            "| Name|Region|UnitsSold|Revenue|\n",
            "+-----+------+---------+-------+\n",
            "| John| North|      100|   NULL|\n",
            "|  Doe|  East|     NULL|     50|\n",
            "|  N/A|  West|      150|     30|\n",
            "|Alice|   N/A|      200|     40|\n",
            "|  Bob| South|     NULL|   NULL|\n",
            "|  N/A|   N/A|     NULL|   NULL|\n",
            "+-----+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.Coalesce Function:\n",
        "  * The coalesce() function returns the first non-null value in a list of columns. Itâ€™s useful when you need to handle missing data by providing alternative values from other columns."
      ],
      "metadata": {
        "id": "hr3cG990SHhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using coalesce() to handle nulls by taking the first non-null value\n",
        "df7 = df.withColumn(\"Adjust_UnitsSold\", coalesce(\"UnitsSold\", \"Revenue\"))\n",
        "df7.show()"
      ],
      "metadata": {
        "id": "rjvlIhBtSMRs",
        "outputId": "5894e9c8-2e88-4f5a-d607-7c225154e256",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---------+-------+----------------+\n",
            "| Name|Region|UnitsSold|Revenue|Adjust_UnitsSold|\n",
            "+-----+------+---------+-------+----------------+\n",
            "| John| North|      100|   NULL|             100|\n",
            "|  Doe|  East|     NULL|     50|              50|\n",
            "| NULL|  West|      150|     30|             150|\n",
            "|Alice|  NULL|      200|     40|             200|\n",
            "|  Bob| South|     NULL|   NULL|            NULL|\n",
            "| NULL|  NULL|     NULL|   NULL|            NULL|\n",
            "+-----+------+---------+-------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Nulls in Aggregations:\n",
        "* Null values can distort aggregate functions like mean(). Using coalesce() in an aggregation ensures that any null values are replaced with a default (e.g., 0.0) to avoid skewing the results."
      ],
      "metadata": {
        "id": "LHYL7uj5UOl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df8 = df.groupBy(\"Region\").agg(coalesce(mean(\"UnitsSold\"),lit(0)).alias(\"Avg_UnitsSold\"))\n",
        "df8.show()"
      ],
      "metadata": {
        "id": "LlJTw2xgUTB9",
        "outputId": "7cb995c3-ceba-4f3b-d3f0-4f9023f19c99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+\n",
            "|Region|Avg_UnitsSold|\n",
            "+------+-------------+\n",
            "|  East|          0.0|\n",
            "|  West|        150.0|\n",
            "| North|        100.0|\n",
            "|  NULL|        200.0|\n",
            "| South|          0.0|\n",
            "+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "adSNDFAGU_Dh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}